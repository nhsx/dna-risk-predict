{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DNAttend - ML framework for predicting patient non-attendance","text":"<p>This model is not currently suitable for predicting patient non-attendance in a real-world healthcare environment.</p> <p>Note: All example data used in this repository is simulated and for illustrative purposes only.</p> <p>See code <code>README</code> for installation and usage instructions. </p>"},{"location":"#overview","title":"Overview","text":"<p>A CatBoost Classifier for predicting patient non-attendance (DNA).</p> <p>DNAttend trains two models independently; a baseline logistic regression model and a CatBoost model. The CatBoost model is trained via a cross-validated randomised hyper-parameter search with over-fit detection. In addition, over-fit detection is performed using a holdout validation set to determine the optimal boosting iterations. Output probability of both models are calibrated via cross-validation.</p> <p>Finally, decision thresholds are tuned, using the training dataset, to optimise either the ROC or F1 score. This choice of threshold metric is determined by the <code>tuneThresholdBy</code> option of the configuration file (defult = f1).</p> <p> </p> <p> Figure: Overview of DNAttend workflow</p>"},{"location":"contact/","title":"Contact","text":"<p>This work was undertaken by during early 2023 by colleagues within the digital analysis and research team (DART) in the Transformtion Directorate of NHS England.</p> <p>See our other open projects here or get in contact by emailing datascience@nhs.net</p>"},{"location":"evaluation/","title":"Output Evaluation","text":""},{"location":"evaluation/#feature-importance","title":"Feature Importance","text":"<pre><code>featureImportances = test.getFeatureImportance(models['catboost']['model'])\nfig = featureImportances.plot.barh()\nfig.figure.savefig('featureImportances.png')\n</code></pre> <p> Figure 1: Feature Importances.</p>"},{"location":"evaluation/#roc-curve","title":"ROC Curve","text":"<pre><code>fig, ax = test.plotROC(models, data)\nfig.figure.savefig('ROCcurve.png')\n</code></pre> <p> Figure 2: Receiver Operating Characteristic curve for both CatBoost and Logistic Model.</p>"},{"location":"evaluation/#precision-recall-curve","title":"Precision-Recall Curve","text":"<pre><code>fig, ax = test.plotPrecisionRecall(models, data)\nfig.figure.savefig('PRcurve.png', dpi=300)\n</code></pre> <p> Figure 3: Precision-Recall curve for both CatBoost and Logistic Model.</p>"},{"location":"evaluation/#calibration-curve","title":"Calibration Curve","text":"<pre><code>fig, ax = test.plotCalibrationCurve(models, data, strategy='quantile')\nfig.figure.savefig('CalibrationCurve.png')\n</code></pre> <p> Figure 4: Calibration curve for both CatBoost and Logistic Model.</p>"},{"location":"evaluation/#evaluation-report","title":"Evaluation Report","text":"<p>The <code>evaluate()</code> function computes a comprehensive set of performance metrics using the <code>test</code> data.</p> <pre><code>report = test.evaluate(models['catboost']['model'], data)\n\nprint(report)\n{\n    'Attend': {\n        'precision': 0.7976354138025845,\n        'recall':    0.7815193965517241,\n        'f1-score':  0.7894951694108042,\n        'support':   3712\n    },\n    'DNA': {\n        'precision': 0.7901138716356108,\n        'recall':    0.8057534969648984,\n        'f1-score':  0.7978570495230629,\n        'support':   3789\n    },\n    'accuracy':      0.7937608318890814,\n    'macro avg': {\n        'precision': 0.7938746427190977,\n        'recall':    0.7936364467583112,\n        'f1-score':  0.7936761094669336,\n        'support':   7501\n    },\n    'weighted avg': {\n        'precision': 0.7938360372833652,\n        'recall':    0.7937608318890814,\n        'f1-score':  0.7937190280623637,\n        'support':   7501\n    }\n}\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>The following sections document the built-in example workflow provided. It is recommended that users follow this workflow to verify proper installation.</p>"},{"location":"usage/#generate-example-data","title":"Generate Example Data","text":"<p>The <code>simulate</code> sub-command generates suitably formatted input data for testing functionality. It also writes an example config file in YAML format. Both of these output files can serve as templates for building real-world models.</p> <pre><code>dnattend simulate --config config.yaml DNAttend-example.csv\n</code></pre>"},{"location":"usage/#train-model","title":"Train Model","text":"<p>DNAttend trains two models independently; a baseline logistic regression model and a CatBoost model. The baseline model is simple model that acts as reference to assess performance improvements of CatBoost.</p> <pre><code>dnattend train config.yaml\n</code></pre>"},{"location":"usage/#evaluate-model","title":"Evaluate Model","text":"<p>Following initial training, the <code>dnattend test</code> command can be used to assess performance of both the logistic regression and CatBoost models against the hold-out testing data set.</p> <pre><code>dnattend test config.yaml\n</code></pre>"},{"location":"usage/#refit-model-with-all-data","title":"Refit Model with All Data","text":"<p>The previous steps have trained two models: a baseline logistic regression model and a more advanced CatBoost. Following parameterisation and assessment of model performance, a final model can be retrained using the entire data set. The user may build a logistic regression or CatBoost model depending on the performance metrics. This choice must be specified by the user in the <code>finalModel:</code> option of the configuration file.</p> <pre><code>dnattend retrain config.yaml\n</code></pre>"},{"location":"usage/#generate-predictions","title":"Generate Predictions","text":"<p>The trained model is now ready to be used. Predictions should be made with the <code>predict</code> module - this ensures the tuned decision threshold is correctly applied when assigning classes. The output of <code>predict</code> includes the decision class (i.e.<code>Attend</code> and <code>DNA</code>) and the underlying probabilities of theses classes.</p> <pre><code>dnattend predict --verify DNAttend-example.csv catboost-final.pkl &gt; FinalPredictions.csv\n</code></pre> <p>Note: the <code>--verify</code> flag is only required when running the example workflow</p> <p>The output results of this example can be found in the <code>example-data-predictions.csv</code> in the <code>docs/assets</code> folder.</p>"},{"location":"usage/#example-workflow-verification","title":"Example Workflow Verification","text":"<p>Following initial installation, it is recommended that users run the example workflow, as described, to verify that the pipeline is functioning as expected. The <code>--verify</code> flag of <code>dnattend predict</code>, as shown above, will check the results against the expected output and notify the user if the output matches or not.</p>"},{"location":"usage/#configuration","title":"Configuration","text":"<p>DNAttend utilises a single configuration file, in YAML, which documents all model parameter and ensure reproducibility of the analysis. The <code>dnattend simulate</code> command writes an example documented configuration file that the user can use as a template. A copy of this file is shown below and available to download as <code>config.yaml</code> in the <code>assets</code> folder.</p> <pre><code>input: DNAttend-example.csv    # Path to input data (Mandatory).\ntarget: status                 # Column name of target (Mandatory).\nDNAclass: 1                    # Value of target corresponding to DNA.\nout: .                         # Output directory to save results.\nfinalModel: catboost           # Method to train final model (catboost or logistic).\ncatCols:                       # Column names of categorical features.\n    - day\n    - priority\n    - speciality\n    - consultationMedia\n    - site\nboolCols:                      # Column names of boolean features.\n    - firstAppointment\nnumericCols:                   # Column names of numeric features.\n    - age\ntrain_size: 0.7                # Proportion of data for training.\ntest_size: 0.15                # Proportion of data for testing.\nval_size: 0.15                 # Proportion of data for validation.\ntuneThresholdBy: f1            # Metric to tune decision threshold (f1 or roc).\ncvFolds: 5                     # Hyper-tuning cross-validations.\ncatboostIterations: 100        # Hyper-tuning CatBoost iterations.\nhypertuneIterations: 5         # Hyper-tuning parameter samples.\nevalIterations: 10_000         # Upper-limit over-fit iterations.\nearlyStoppingRounds: 10        # Over-fit detection early stopping rounds.\nseed: 42                       # Seed to ensure workflow reproducibility.\n</code></pre>"}]}